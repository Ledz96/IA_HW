state =
	(current_city, task_destination)	if task
	(current_city, null)				if not task

action = (destination_city, deliver_task)
	during learning, only possible actions are available (action with deliver_task == true only for task_destination)
	maybe only neighbors of current_city instead of all possible destinations?

reward(s,a) =
	task_reward - task_cost [task_weight * movement_cost]		if task
	movement_cost												if not task

probability of transition T(s,a,s') = TaskDistribution.probability(destination_city, new_destination_city)